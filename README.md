# Official PyTorch Implementation of SAV 



* **Segment Any Vehicle: Semantic and Visual Context Driven SAM and A Benchmark**,
  Xiao Wang, Ziwen Wang, Wentao Wu, Anjie Wang, Jiashu Wu, Yantao Pan, Chenglong Li
  arXiv:2508.04260 [[Paper](https://arxiv.org/abs/2508.04260)] 




### Abstract 
With the rapid advancement of autonomous driving, vehicle perception, particularly detection and segmentation, has placed increasingly higher demands on algorithmic performance. Pre-trained large segmentation models, especially Segment Anything Model (SAM), have sparked significant interest and inspired new research directions in artificial intelligence. However, SAM cannot be directly applied to the fine-grained task of vehicle part segmentation, as its text-prompted segmentation functionality is not publicly accessible, and the mask regions generated by its default mode lack semantic labels, limiting its utility in structured, category-specific segmentation tasks. To address these limitations, we propose SAV, a novel framework comprising three core components: a SAM-based encoder-decoder, a vehicle part knowledge graph, and a context sample retrieval encoding module. The knowledge graph explicitly models the spatial and geometric relationships among vehicle parts through a structured ontology, effectively encoding prior structural knowledge. Meanwhile, the context retrieval module enhances segmentation by identifying and leveraging visually similar vehicle instances from training data, providing rich contextual priors for improved generalization. Furthermore, we introduce a new large-scale benchmark dataset for vehicle part segmentation, named VehicleSeg10K, which contains 11,665 high-quality pixel-level annotations across diverse scenes and viewpoints. We conduct comprehensive experiments on this dataset and two other datasets, benchmarking multiple representative baselines to establish a solid foundation for future research and comparison. % Both the dataset and source code of this paper will be released upon acceptance. 



### Framework 





### VehicleSeg10K Benchmark Dataset 

* **Baidu Drive**
```
链接: https://pan.baidu.com/s/1v0_VfTfzvdxqWw0TG4Ifsw?pwd=8bfb 提取码: 8bfb
```

* **Dropbox**
```
https://www.dropbox.com/scl/fi/tgtdboa4pxa7rtfg9ag52/VehicleSeg10K.zip?rlkey=ex4ssmgb21agqyvg0rysbl9pv&st=o14a1fo3&dl=0
```


### Environment Configuration 
We use conda to manage the environment.

Pytorch installation:
```commandline
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 cuda -c pytorch  -c "nvidia/label/cuda-12.1.0" -c "nvidia/label/cuda-12.1.1"
```

mmengine installation:
```commandline
python -m pip install https://github.com/open-mmlab/mmengine/archive/refs/tags/v0.8.5.zip
```

mmcv installation (note that older version mmcv before this commit may cause bugs):
```commandline
TORCH_CUDA_ARCH_LIST="{COMCAP}" TORCH_NVCC_FLAGS="-Xfatbin -compress-all" CUDA_HOME=$(dirname $(dirname $(which nvcc))) LD_LIBRARY_PATH=$(dirname $(dirname $(which nvcc)))/lib MMCV_WITH_OPS=1 FORCE_CUDA=1 python -m pip install git+https://github.com/open-mmlab/mmcv.git@4f65f91db6502d990ce2ee5de0337441fb69dd10
```


### Training and Testing 
Please extract the language embeddings first.
```commandline
bash tools/dist.sh gen_cls seg/configs/ovsam/ovsam_coco_rn50x16_point.py 8
```
CLIP2SAM training:
```commandline
bash tools/dist.sh train seg/configs/clip2sam/clip2sam_coco_rn50x16_prompt4.py 8
```
Inference
```commandline
bash tools/dist.sh test seg/configs/ovsam/ovsam_coco_rn50x16_point_prompt_all_prompt4.py 8
```


### Experimental Results and Visualization 



### Acknowledgement 
[[SAM](https://github.com/facebookresearch/segment-anything)] 
[[3DRealCar](https://github.com/xiaobiaodu/3DRealCar_Toolkit)] 
[[CLIP](https://github.com/openai/CLIP)] 


### Citation 
```
@misc{wang2025SAV,
      title={Segment Any Vehicle: Semantic and Visual Context Driven SAM and A Benchmark}, 
      author={Xiao Wang and Ziwen Wang and Wentao Wu and Anjie Wang and Jiashu Wu and Yantao Pan and Chenglong Li},
      year={2025},
      eprint={2508.04260},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.04260}, 
}
```









